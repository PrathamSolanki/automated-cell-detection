{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WMeCOQ-a0Tic"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image, ImageDraw\n",
    "import xml.etree.ElementTree as ET\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SDV3Rf_I2IIX"
   },
   "outputs": [],
   "source": [
    "class TissueDataset(Dataset):\n",
    "\n",
    "    def __init__(self, img_dir='data/images', annotation_dir='data/annotations', transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.annotation_dir = annotation_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.img_names = os.listdir(img_dir)\n",
    "        self.img_names = [filename for filename in self.img_names if filename.endswith('png')]\n",
    "        self.img_names.sort()\n",
    "        self.img_names = [os.path.join(img_dir, img_name) for img_name in self.img_names]\n",
    "\n",
    "        self.annotation_names = os.listdir(annotation_dir)\n",
    "        self.annotation_names = [filename for filename in self.annotation_names if filename.endswith('xml')]\n",
    "        self.annotation_names.sort()\n",
    "        self.annotation_names = [os.path.join(annotation_dir, ann_name) for ann_name in self.annotation_names]\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_names[idx]\n",
    "        img = Image.open(img_name)\n",
    "\n",
    "        annotation_name = self.annotation_names[idx]\n",
    "        annotation_tree = ET.parse(annotation_name)\n",
    "        objects = annotation_tree.findall(\"object\")\n",
    "        bndboxes = []\n",
    "        labels = []\n",
    "        \n",
    "        for object in objects:\n",
    "            label = int(object.find(\"name\").text)\n",
    "            bndbox_xml = object.find(\"bndbox\")\n",
    "                \n",
    "            xmax = int(bndbox_xml.find('xmax').text) \n",
    "            ymax = int(bndbox_xml.find('ymax').text)\n",
    "            xmin = int(bndbox_xml.find('xmin').text)\n",
    "            ymin = int(bndbox_xml.find('ymin').text)\n",
    "\n",
    "            w = xmax - xmin #\n",
    "            h = ymax - ymin\n",
    "            x = int(xmin + w / 2)\n",
    "            y = int(ymin + h / 2)\n",
    "\n",
    "            x /= img.size[0]\n",
    "            w /= img.size[0]\n",
    "            y /= img.size[1]\n",
    "            h /= img.size[1]\n",
    "\n",
    "            bndbox = (x, y, w, h)\n",
    "            \n",
    "            labels.append(label)\n",
    "            bndboxes.append(bndbox)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        bndboxes = torch.tensor(bndboxes)\n",
    "        labels = torch.tensor(labels)\n",
    "        \n",
    "        annotations = {}\n",
    "        annotations['boxes'] = bndboxes\n",
    "        annotations['labels'] = labels\n",
    "\n",
    "        return img, annotations\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform():\n",
    "    custom_transforms = []\n",
    "    custom_transforms.append(torchvision.transforms.ToTensor())\n",
    "    return torchvision.transforms.Compose(custom_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PPHjcqiR4aP0"
   },
   "outputs": [],
   "source": [
    "tissueDataset = TissueDataset(transform=get_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(tissueDataset,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=True,\n",
    "                                         collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "nROtBG8h5QLH",
    "outputId": "4bfa3798-7575-46df-a282-e548756e2488"
   },
   "outputs": [],
   "source": [
    "# select device (whether GPU or CPU)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# DataLoader is iterable over Dataset\n",
    "for imgs, annotations in data_loader:\n",
    "    imgs = list(img.to(device) for img in imgs)\n",
    "    annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
    "    print(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6cCbCg-W5UKA"
   },
   "outputs": [],
   "source": [
    "def UnpackBndbox(bndbox, img):\n",
    "    x, y, w, h = tuple(bndbox)\n",
    "    x *= img.size[0] \n",
    "    w *= img.size[0]\n",
    "    y *= img.size[1]\n",
    "    h *= img.size[1]\n",
    "    xmin = x - w / 2\n",
    "    xmax = x + w / 2\n",
    "    ymin = y - h / 2\n",
    "    ymax = y + h / 2\n",
    "    bndbox = [xmin, ymin, xmax, ymax]\n",
    "    return bndbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TJkKSel35bQB"
   },
   "outputs": [],
   "source": [
    "def Show(batch, pred_bndbox=None):\n",
    "    img, annotations = batch\n",
    "\n",
    "    img = transforms.ToPILImage()(img)\n",
    "    img = transforms.Resize((512, 512))(img)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    for bndbox in annotations['boxes']:\n",
    "        bndbox = UnpackBndbox(bndbox, img)\n",
    "        draw.rectangle(bndbox)\n",
    "        if pred_bndbox is not None:\n",
    "            pred_bndbox = unpack_bndbox(pred_bndbox, img)\n",
    "            draw.rectangle(pred_bndbox, outline=1000)\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fn4R5inU5dUR"
   },
   "outputs": [],
   "source": [
    "Show(tissueDataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = model.roi_heads.box_predictor.cls_score.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "len_dataloader = len(data_loader)\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    i = 0    \n",
    "    for imgs, annotations in data_loader:\n",
    "        i += 1\n",
    "        imgs = list(img.to(device) for img in imgs)\n",
    "        annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
    "        loss_dict = model(imgs, annotations)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Iteration: {i}/{len_dataloader}, Loss: {losses}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Definiens_SOLANKI.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
