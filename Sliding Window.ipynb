{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sliding Window.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF6TpneAWnFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import imutils\n",
        "import time\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import torch\n",
        "from copy import deepcopy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4DYQex1l2So",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ReadCellImages(dir, imgSize):\n",
        "  images = os.listdir(dir)\n",
        "  images = [image for image in images if image.endswith('png')]\n",
        "\n",
        "  X = np.empty([len(images),imgSize[0],imgSize[1],3], dtype=float)\n",
        "  y = []\n",
        "\n",
        "  count = 0\n",
        "  for image in images:\n",
        "    X[count] = cv2.imread(dir+image)#.reshape((1,-1))\n",
        "    if '1' in image: y.append(0)\n",
        "    elif '2' in image: y.append(1)\n",
        "    elif '3' in image: y.append(2)\n",
        "    count = count+1\n",
        "\n",
        "  return (X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmSAPvUmnqcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = ReadCellImages('cells/', (23,23))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyaoE-WwtwMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def CreateBatch(data, index, batch_size):\n",
        "  if index + batch_size > len(data[0]): batch_size = len(data[0]) - index - 1\n",
        "  return (torch.cat(\n",
        "      [torch.from_numpy(image).float().reshape(1, 3, 23, 23) for image in data[0][index:index + batch_size]], dim=0), \n",
        "      torch.tensor(data[1][index:index + batch_size], dtype=torch.long)\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKICYR9uuvFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN_classifier(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv_model = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "    )\n",
        "\n",
        "    self.linear = torch.nn.Linear(in_features=32*10*10,out_features=3)\n",
        "\n",
        "  def forward(self, batch):\n",
        "    z = batch\n",
        "    z = self.conv_model(z)\n",
        "    z = z.view(-1, 32*10*10)\n",
        "    return self.linear(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lEyN6eYwE89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn = CNN_classifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px4hImh4wHMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.SGD(\n",
        "    cnn.parameters(),\n",
        "    lr=0.01\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CLrrvHfwJNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_builder = torch.nn.NLLLoss(reduction='mean')\n",
        "m = torch.nn.LogSoftmax(dim=1)\n",
        "s = torch.nn.Softmax(dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRV4etHgwLKf",
        "colab_type": "code",
        "outputId": "834e0cdb-27fe-4439-a61d-ac3ee298adf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        }
      },
      "source": [
        "batch_size = 3\n",
        "n_epochs = 10\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  cnn.train()\n",
        "  for i in range(0,len(train_data[0]),batch_size):\n",
        "    batch = CreateBatch(train_data, i, batch_size)\n",
        "    x = batch[0]\n",
        "    gold = batch[1]\n",
        "    y = cnn(x)\n",
        "    loss = loss_builder(m(y),gold)\n",
        "\n",
        "    cnn.zero_grad()\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_value_(cnn.parameters(), 5.)  # clip gradient if its norm exceed 5\n",
        "    optimizer.step()\n",
        "\n",
        "  cnn.eval()\n",
        "  train_acc = 0\n",
        "  for i in range(0,len(train_data[0]),1):\n",
        "    batch = CreateBatch(train_data, i, 1)\n",
        "    x = batch[0]\n",
        "    gold = batch[1]\n",
        "    y = cnn(x)\n",
        "\n",
        "    if np.max(s(y).detach().numpy()) < 0.9: gold_predicted = 3\n",
        "    else: gold_predicted = np.argmax(s(y).detach().numpy())\n",
        "\n",
        "    if gold_predicted == gold: train_acc += 1\n",
        "\n",
        "  train_acc /= train_data[0].shape[0]\n",
        "  \n",
        "  train_loss_list.append(loss.item())\n",
        "  train_acc_list.append(train_acc)\n",
        "\n",
        "  print(\"Epoch: {:d}/{:d}\".format(epoch+1,n_epochs))\n",
        "  print (\"Train Avg Loss:\", loss.item(), \"\\t\\tTrain Accurancy:\", train_acc)\n",
        "  print()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/10\n",
            "Train Avg Loss: 48.87565994262695 \t\tTrain Accurancy: 0.3333333333333333\n",
            "\n",
            "Epoch: 2/10\n",
            "Train Avg Loss: 4265.38037109375 \t\tTrain Accurancy: 0.6666666666666666\n",
            "\n",
            "Epoch: 3/10\n",
            "Train Avg Loss: 389.4669494628906 \t\tTrain Accurancy: 1.0\n",
            "\n",
            "Epoch: 4/10\n",
            "Train Avg Loss: 0.0 \t\tTrain Accurancy: 1.0\n",
            "\n",
            "Epoch: 5/10\n",
            "Train Avg Loss: 0.0 \t\tTrain Accurancy: 1.0\n",
            "\n",
            "Epoch: 6/10\n",
            "Train Avg Loss: 0.0 \t\tTrain Accurancy: 1.0\n",
            "\n",
            "Epoch: 7/10\n",
            "Train Avg Loss: 0.0 \t\tTrain Accurancy: 1.0\n",
            "\n",
            "Epoch: 8/10\n",
            "Train Avg Loss: 0.0 \t\tTrain Accurancy: 1.0\n",
            "\n",
            "Epoch: 9/10\n",
            "Train Avg Loss: 0.0 \t\tTrain Accurancy: 1.0\n",
            "\n",
            "Epoch: 10/10\n",
            "Train Avg Loss: 0.0 \t\tTrain Accurancy: 1.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "htMqKafQQsIR",
        "colab": {}
      },
      "source": [
        "def SlidingWindow(image, stepSize, windowSize):\n",
        "\tfor y in range(0, image.shape[0], stepSize):\n",
        "\t\tfor x in range(0, image.shape[1], stepSize):\n",
        "\t\t\tyield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5hBjVjPW5B1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = cv2.imread('black_bubbles_1.png')\n",
        "(winW, winH) = (23, 23)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7xHoU1DXiRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cell_1_count = 0\n",
        "cell_2_count = 0\n",
        "cell_3_count = 0\n",
        "\n",
        "for (x, y, window) in SlidingWindow(image, stepSize=1, windowSize=(winW, winH)):\n",
        "\tif window.shape[0] != winH or window.shape[1] != winW:\n",
        "\t\tcontinue\n",
        "\n",
        "\tcnn.eval()\n",
        "\twindow_reshaped = deepcopy(window)\n",
        "\twindow_reshaped = window_reshaped.reshape((1,3,23,23))\n",
        "\tbatch = CreateBatch((window_reshaped,[0,0,0]), 0, 1)\n",
        "\tpatch = batch[0]\n",
        "\tgold = batch[1]\n",
        "\tpred = cnn(patch)\n",
        "\tif np.max(s(pred).detach().numpy()) >= 0.9:\n",
        "\t\tpred = np.argmax(s(pred).detach().numpy())\n",
        "\t\tif pred == 0: cell_1_count = cell_1_count + 1\n",
        "\t\telif pred == 1: cell_2_count = cell_1_count + 1\n",
        "\t\telif pred == 2: cell_3_count = cell_1_count + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDut8rN350mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Cell Type 1 Count', cell_1_count)\n",
        "print('Cell Type 2 Count', cell_2_count)\n",
        "print('Cell Type 3 Count', cell_3_count)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}